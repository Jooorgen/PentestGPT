import dataclasses
import requests
import uuid
import ollama

from typing import Any, Dict, List, Optional
from tenacity import retry, stop_after_attempt, wait_fixed  

from pentestgpt.utils.llm_api import LLMAPI 

@dataclasses.dataclass
class Message:
    ask_id: str = None
    ask: dict = None
    answer: dict = None
    answer_id: str = None
    request_start_timestamp: float = None
    request_end_timestamp: float = None
    time_escaped: float = None

@dataclasses.dataclass
class Conversation:
    conversation_id: str = None
    message_list: List[Message] = dataclasses.field(default_factory=list)

    def __hash__(self):
        return hash(self.conversation_id)

    def __eq__(self, other):
        if not isinstance(other, Conversation):
            return False
        return self.conversation_id == other.conversation_id

class OllamaAPI(LLMAPI):
    def __init__(self, config_class, use_langfuse_logging=False):
        self.name = str(config_class.model)  

        # Adjust API endpoint if needed:
        self.api_base = config_class.api_base 

        # OLLAMA client setup
        self.client = ollama.Client(host=self.api_base) 

        # Initialize conversation tracking
        self.conversation_dict: Dict[str, Conversation] = {} 

        self.model = config_class.model

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2)) 
    def _send_to_ollama(self, prompt: str) -> str:
        try:
            response = self.client.chat(model=self.name, messages=[
                {"role": "user", "content": prompt}
            ]) 
            return response["message"]["content"]  
        except ollama.ResponseError as e: # Add error handling from the 'ollama' library
            raise Exception(f"Ollama request failed: {e.error}") from e
        except Exception as e: # Catch other potential errors
            raise Exception(f"Ollama request error: {e}") from e 

    def send_new_message(self, message: str, conversation_id: Optional[str] = None) -> tuple[str, str]:
        if conversation_id is None:
            conversation_id = str(uuid.uuid1())
            print(conversation_id)
            self.conversation_dict[conversation_id] = Conversation(conversation_id=conversation_id) 

        conversation = self.conversation_dict[conversation_id]

        # Construct the prompt for Ollama (only send the current message)
        prompt = message

        response = self._send_to_ollama(prompt)

        # Update the conversation history
        conversation.message_list.append(Message(ask=message, answer=response))

        return response, conversation_id 

    def send_message(self, message: str, conversation_id: str) -> str:
        print(conversation_id)
        if conversation_id not in self.conversation_dict:
            raise ValueError(f"Conversation ID {conversation_id} not found.")

        conversation = self.conversation_dict[conversation_id]

        # Reconstruct the prompt for Ollama 
        prompt = ""
        for msg in conversation.message_list:
            prompt += f"User: {msg.ask}\nAssistant: {msg.answer}\n"
        prompt += f"User: {message}\n" 

        response = self._send_to_ollama(prompt)

        # Update the conversation history
        conversation.message_list.append(Message(ask=message, answer=response))

        return response 

if __name__ == "__main__":
    # Example for testing 
    api_url = "http://localhost:11434/api/generate" 
    model_name = "model-name-in-ollama" 

    prompt = "What is the difference between XSS and CSRF?"
    response = requests.post(
        api_url, 
        json={"model": model_name, "prompt": prompt},
    ) 

    if response.status_code == 200:
        print(response.json()["text"]) 
    else:
        print(f"Request failed with status: {response.status_code}")
